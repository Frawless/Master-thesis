% (c) Jakub Stejskal
% Master Thesis
% Performance Testing and Analysis of Qpid-Dispatch Router
% Chapter 7

\chapter{Future works and ideas}
\label{Future works and ideas}
The Maestro is currently used for performance testing of Messaging Broker and Qpid-dispatch in Red Hat Messaging team. This makes the Maestro one of the key utilities for the Messaging and the primary performance tool. Since the Maestro is basically young system, there is a lot of place for improvements. Few ideas are described in the following. Note, that Maestro-Agent and AMQP Inspector are new Maestro modules, which makes available performance testing of Qpid-dispatch with collecting interior data about SUT itself. This extension are available since Maestro stable version 1.3.0.

\section{Regression Testing}
Since Messaging Broker and Qpid-dispatch has new builds every few weeks, there can be performance regression degradation. This issues can be caused by one simple commit, which can fix some issues but broker performance with it. However, Maestro can reveal performance degradation, if there is already measured data with specific informations. Maestro can re-run the same test with new version of SUT and compare the collected results with previous data set.

This mechanism is very simple to achieve. The first step is to configure pipeline job on some orchestration and integration system such as Jenkins or Travis CI. This job has to have access to SUT repository and data tagged as a performance standard for the SUT. The trigger of this job can be every push or tagged commit. The other steps is extension of the Maestro-Reporter, where it can compare older data with new collected data and say, how much they are different and where. This pipeline job then can tells to engineers, that some specific commit caused performance degradation and also show the difference between actual collected data and estimate collected data.

The type of testing can be also applicable to all test cases with different SUT configuration. The Maestro would be able to compare expected data with collected data and tell us that this specific configuration has performance degradation.

\section{Data Reporting}
The current reports, created by Maestro itself, contains charts, that are in the png format. This makes them less informative that they could be with better data visualization. Since Inspectors collecting additional data about SUT, for example about memory usage, it will be helpful for engineers of SUT to see interactive charts with collected data. With this options, engineers can better analyze what is going on with SUT during the test scenario.

Good example of interactive and vector charts is \emph{Grafana}\footnote{Grafana\,---\,open source software for time series analytics \url{https://grafana.com/}}. Grafana can produce awesome graphics outputs from collected data saved let say in the database. Another example for plot collected data is \emph{Project Jupyter}\footnote{Jupyter\,---\,\url{http://jupyter.org/}}. This solution offers plot interactive charts from database source data on the fly. One only needs installed python on the node. Jupyter starts python server on the node and make plotted data available via the HTTP browser. Maestro can implement this, as a new peer similar to data server code, which is running on all Maestro peer nodes. The difference is, that this reports server will be started by Maestro-Reporter on the execution node.

\section{Collected Data Compression}
Each Maestro peer collects different data during the test. Size of that data is based on peer type, collected data format and test duration. For example the Maestro-Receiver collect huge amount of time for throughput and latency chart. These data are are represented as a double-column csv file with columns \emph{eta}(estimated time of arrival) and \emph{ata}(actual time of arrival). Each csv line looks like the following:

\begin{verbatim}
  eta;ata
  "2017-10-19 13:19:32.661300","2017-10-19 13:19:32.706649"
  "2017-10-19 13:19:32.661500","2017-10-19 13:19:32.706823"
\end{verbatim}

Imagine, that this record is written for each send/received message on sender or receiver. For example we can have 50\,000 records with prefix \texttt{"2017-10-19 13:19:32"} which is not efficient. The idea is, that we can save first timestamp and then only compute difference between saved timestamp and current timestamp and write this difference into csv file. We can save here at least 15\,Bytes per timestamp, which saves more than one half of current size. Only thing is to write new timestamp after some time, when difference is going to be too big. The new csv file could looks like the following:

\begin{verbatim}
  eta;ata
  1525285541559,1525285560346
  +30,+40
  +35,+42
\end{verbatim}

\section{Multi-point Senders and Receiver}
With behavioral testing comes an idea with multipoint senders and receivers. Lets say, that we want to collect behavioral data about Qpid-dispatch with two queues, where the first queue accepts messages from two senders and the second queue accepts messages from five senders. This situation is better simulation of real network traffic the current mechanism. To achieve this, the Maestro needs to extend Maestro-Worker with option for multiple endpoint connections dynamically. Current version offers only one specific connection specified by user.

\section{Maestro-Agent Executor Improvements}
The Maestro-Agent is able to download external git repositories and tries to process them during the test. However, the external code handler is currently designed only for process code written in Groovy. This limitation can be easily removed by create more general executor, which is able to execute any type of scripts with get the execute output. One idea how to achieve this is to create more complex executor in \emph{Kotlin} languange\footnote{Kotlin\,---\,\url{https://kotlinlang.org/}}. New executor should be able to run each type of downloaded script and keep the access to the return code and standard output. This extension will remove the limitation to the use, which has to specify each external action handler in the Groovy language, which can be uncomfortable. Note, that new executor should not affect performance testing during the execution, so the operation should remain atomic unless we want otherwise behavior.
