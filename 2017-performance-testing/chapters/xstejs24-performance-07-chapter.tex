% (c) Jakub Stejskal
% Master Thesis
% Performance Testing and Analysis of Qpid-Dispatch Router
% Chapter 7

\chapter{Future works and ideas}
\label{Future works and ideas}
The Maestro is currently used for performance testing of Apache ActiveMQ Artemis and Qpid-dispatch in Red Hat Messaging QE team. This makes the Maestro one of the key utilities for the Messaging and the primary performance tool. But since the Maestro is basically immature system, there is still a lot of places for improvements. We present several ideas in the following. Note, that Maestro-Agent and AMQP Inspector are new Maestro modules, which makes performance testing of Qpid-dispatch with collecting interior data about SUT itself available. These extensions were already merged in the upstream and are available since Maestro stable version 1.3.0.

\section{Regression Testing}
Since both message broker and message router have new builds every few weeks, there can occur a performance degradation. This issue can be caused by just one simple commit, which can fix some issues but break performance. However, Maestro can catch such performance degradation early in the process, if there is already previously measured data with specific informations (so called baselines). Maestro can then re-run the same test with new version of SUT and compare the collected results with previous the data set.

This mechanism is simple to achieve. The first step is to configure the pipeline job on the orchestration and integration system such as Jenkins or Travis CI. This job has to have access to SUT repository and baseline data tagged as a performance standard for the SUT. The trigger of this pipeline can be every push or every commit with specific tag. The other step is the extension of the Maestro-Reporter, where it can compare older data with newly collected ones and report, how much they differ and where. This pipeline job then can alert engineers, that some specific commit caused performance degradation and also show the difference between actual collected data and estimate collected data.

This type of testing can also be applicable to all test cases with different SUT configuration. The Maestro would be able to compare expected data with collected data and tell us that this specific configuration has a performance degradation.

\section{Data Reporting}
The current reports, created by Maestro itself, contain charts, in the \emph{png} format generated by the Java library for creating bitmap figures. This makes them less informative that they could be with better data visualization. Since Inspectors collect additional data about SUT, e.g. memory usage, it will be helpful for engineers of SUT to see interactive charts with collected data. With this options, engineers can better analyze what is going on with SUT during the test scenario.

A~good example of interactive and vector charts library is \emph{Grafana}\footnote{Grafana\,---\,open source software for time series analytics \url{https://grafana.com/}}. Grafana can produce awesome outputs from collected data e.g. from the database. Another example is \emph{Project Jupyter}\footnote{Jupyter\,---\,\url{http://jupyter.org/}}, which can plot interactive charts from database source data on the fly. One only needs installed Python on the node. Jupyter starts a Python server on the node and makes plotted data available via the HTTP browser. Maestro can implement such strategy, as a new peer similar to the data server code, which is running on all Maestro peer nodes. The difference is, that this report server will be started by Maestro-Reporter on the execution node.

\section{Collected Data Compression}
Each Maestro peer collects different data during the test. Size of these data is based on peer type, collected data format and test duration. For example the Maestro-Receiver collects huge amount of time for throughput and latency chart. These data are represented as a double-column csv file with columns \emph{eta}(estimated time of arrival) and \emph{ata}(actual time of arrival). Each csv file looks like the following:

\begin{verbatim}
  eta;ata
  "2017-10-19 13:19:32.661300","2017-10-19 13:19:32.706649"
  "2017-10-19 13:19:32.661500","2017-10-19 13:19:32.706823"
\end{verbatim}

Imagine, that this record is written for each send/received message on sender or receiver. For example we can have 50,000 records with prefix \texttt{"2017-10-19 13:19:32"} which represents a huge redundancy. The idea of compression is to save only first timestamp and then compute difference between saved timestamp and current timestamp and write this difference into csv file. This way would be able to save at least 15\,B per timestamp, which saves more than one half of current size. The only necessary thing is to write a new timestamp after some time, when difference is too big. The new csv file would then look like the following:

\begin{verbatim}
  eta;ata
  1525285541559,+18787
  +30,+40
  +35,+42
\end{verbatim}

\section{Multi-point Senders and Receiver}
Behavioral testing introduces an idea of multipoint senders and receivers. Lets say, that we want to collect behavioral data about Qpid-dispatch with two queues, where the first queue accepts messages from two senders and the second queue accepts messages from five senders. This situation better simulates the real network traffic than the current mechanism. To achieve this, the Maestro needs to extend Maestro-Worker with option for multiple endpoint connections dynamically. The current version offers only one specific connection specified by the user.

\section{Maestro-Agent Executor Improvements}
The Maestro-Agent is able to download external git repositories and tries to process them during the test. However, the external code handler is currently designed only for code written in Groovy. This limitation can be easily removed by creating more general executor, which would be able to execute any type of scripts. One idea how to achieve this is to create more complex executor in \emph{Kotlin} languange\footnote{Kotlin\,---\,\url{https://kotlinlang.org/}}. The new executor should be able to run each type of downloaded script and keep the access to the return code and standard output. This extension would remove the limitation to use, which has to specify each external action handler in the Groovy language. Note, that new executor should not affect performance testing during the execution, so the operations should remain atomic.

\section{Multiple Agents and Inspectors}
Version of Maestro 1.3.0 has already integrated Maestro Agent and AMQP Inspector. However, the front-end API does not allows setting for multiple Agents or Inspectors during one test scenario. Hence, only one Agent and one Inspector can be specified by Groovy test script. The solution for this problem must involve dynamic scan of specific environment variables which will contains setting for the Maestro components. The settings can be loaded into the array of Agent/Inspector setting and then can be assigned to a specific component by the node URL.

% \section{Problems}
% \todo{Todo - popsat nebo vypustit?}
% \begin{itemize}
%   \item \textbf{Jenkins}\,---\,the idea was to have jobs in Jenkins\footnote{Jenkins\,---\,\url{https://jenkins.io/}} but Maestro does not like Jenkins without reason, probably some hidden issue
%   \item \textbf{QpidJMS}\,---\,QpidJMS is not able to fill MapMessage body by default only via undocumented feature, the developer consultaiton was needed.
%   \item \textbf{Qpid-Dispatch}\,---\,performance degradation in line topology was discussed with engineers and it was said: "it is ok, it's flow control".
%   \item \textbf{Agent and Inspector on same node}\,---\,this sometimes cause the problem (caused by data server which is binded to node) that test will not be ended properly (try it).
% \end{itemize}
